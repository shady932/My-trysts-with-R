---
title: "R Notebook"
output: wrd_document
---

Hypothesis: Does feature selection using LASSO or Important Variable for SVM fit, help with the performance on classification of potential employees (from turn-outs at data science training camps organisqed by a particular Corp)? 



```{r}
#Dependencies

library(e1071)
library(glmnet)
library(caret)
library(plyr)
library(penalizedSVM)
library(WeightSVM)
library(ggplot2)
library('binaryLogic')
library("caTools")
library('car')
library('dplyr')
library(factoextra)
library(lars)
library(kernlab)
library(coefplot)
library(bmrm)
`%ni%`<-Negate(`%in%`)

```

```{r}
bin_en2 <- function(data, x, order = unique(x), name = "V") {
  name1<-paste0(name,"_")
  x <- as.numeric(factor(x, levels = order, exclude = NULL))
  x2 <- as.binary(x)
  maxlen <- max(sapply(x2, length))
  x2 <- lapply(x2, function(y) {
    l <- length(y)
    if (l < maxlen) {
      y <- c(rep(0, (maxlen - l)), y)
    }
    y
  })
  d <- as.data.frame(t(as.data.frame(x2)))
  rownames(d) <- NULL
  colnames(d) <- paste0(name1, 1:maxlen)
  thugs<-cbind(data %>% select(-c(name)) ,d)
  thugs
}
```



```{r}
setwd('C:/Users/SASWATA/Desktop/Study ebooks/Sem 6/CSE4029/SVM')
train<-read.csv('aug_train.csv')
test<-read.csv('aug_test.csv')
print('Training data size:')
dim(train)
print('Test data size:')
dim(test)


```

Following are some Features of the dataset.

enrollee_id : Unique ID for candidate

city: City code

city_ development _index : Developement index of the city (scaled)

gender: Gender of candidate

relevent_experience: Relevant experience of candidate

enrolled_university: Type of University course enrolled if any

education_level: Education level of candidate

major_discipline :Education major discipline of candidate

experience: Candidate total experience in years

company_size: No of employees in current employer's company

company_type : Type of current employer

lastnewjob: Difference in years between previous job and current job

training_hours: training hours completed

target: 0 – Not looking for job change, 1 – Looking for a job change



First we do some basic EDA and pre-processing.

```{r}
#Does the data have missing values?
sum(is.na(train))

#There are no NA values in the data.

#Let us check the number of unique values in each feature.
apply(train,2,plyr::count)

#Observations:
#!. Class imbalance in the ratio of 3:1 for negative class.
#2. enrollee_id is an indexing parameter, will not take part in prediction.
#3. city has very uneven distribution, may skew the prediction in favor of larger representation.
#4. There are no NAs but there are lots of NULL values (empty strings).

#Order of dropping NULL strings: gender, company_type, major_discipline, education_level, experience, lastnewjob, company_size

#The features are ordered from most likely known and lost in transmission to least likely known. Though, there is not much difference in that regard.

train<-train[train$gender!="",]
train<-train[train$company_type!="",]
train<-train[train$major_discipline!="",]
train<-train[train$education_level!="",]
train<-train[train$experience!="",]
train<-train[train$last_new_job!="",]
train<-train[train$company_size!="",]

test<-test[test$gender!="",]
test<-test[test$company_type!="",]
test<-test[test$major_discipline!="",]
test<-test[test$education_level!="",]
test<-test[test$experience!="",]
test<-test[test$last_new_job!="",]
test<-test[test$company_size!="",]

print('Training data final size:')
dim(train)
print('Test data final size:')
dim(test)

```


Categorical Encoding of string features

```{r}

#Now, we look at the characteristics of each attribute.
summary(train)

#Clearly there are a lot of character attributes, we may need to numerically encode these to study their mode and effect on dependent variable.

#Let us look at the distribution of target classes wrt to all other features.

gpf<-function(i){
  if(class(i)=="character"){
    ggplot(train, aes(x=enrollee_id,y=as.integer(factor(i,levels = unique(i))),colour=target))+
      geom_point()
  }
  else{
    ggplot(train, aes(x=enrollee_id,y=i,colour=target))+
      geom_point()
  }
}

apply(train,2,gpf)


```


```{r}

#Observations:
#1. last_new_job should be continuous instead of categorical.
#2. Nominal features: company_type, major_discipline, enrolled_university, relevent_experience, gender, city, enrolled_university
#3. Ordinal features: company_size, experience, education_level, city_ development _index

#We will deal with nominal features by binary encoding and ordinal features by nominal encoding.


#We will create a copy of the data with categorical versions of string features.

trainc<-train
testc<-test

#Nominal:
trainc<-bin_en2(trainc,trainc$company_type,name = "company_type")
trainc<-bin_en2(trainc,trainc$major_discipline,name = "major_discipline")
trainc<-bin_en2(trainc,trainc$relevent_experience,name = "relevent_experience")
trainc<-bin_en2(trainc,trainc$gender,name = "gender")
trainc<-bin_en2(trainc,trainc$city,name = "city")
trainc<-bin_en2(trainc,trainc$enrolled_university,name = "enrolled_university")

testc<-bin_en2(testc,testc$company_type,name = "company_type")
testc<-bin_en2(testc,testc$major_discipline,name = "major_discipline")
testc<-bin_en2(testc,testc$relevent_experience,name = "relevent_experience")
testc<-bin_en2(testc,testc$gender,name = "gender")
testc<-bin_en2(testc,testc$city,name = "city")
testc<-bin_en2(testc,testc$enrolled_university,name = "enrolled_university")

#Ordinal:
trainc$company_size<-as.integer(factor(trainc$company_size,levels = unique(trainc$company_size),exclude = NULL))
trainc$experience<-as.integer(factor(trainc$experience,levels = unique(trainc$experience),exclude = NULL))
trainc$education_level<-as.integer(factor(trainc$education_level,levels = unique(trainc$education_level),exclude = NULL))
trainc$city_development_index<-as.integer(factor(trainc$city_development_index,levels = unique(trainc$city_development_index),exclude = NULL))

testc$company_size<-as.integer(factor(testc$company_size,levels = unique(testc$company_size),exclude = NULL))
testc$experience<-as.integer(factor(testc$experience,levels = unique(testc$experience),exclude = NULL))
testc$education_level<-as.integer(factor(testc$education_level,levels = unique(testc$education_level),exclude = NULL))
testc$city_development_index<-as.integer(factor(testc$city_development_index,levels = unique(testc$city_development_index),exclude = NULL))


trainc[trainc$last_new_job=="never","last_new_job"]<-"0"
testc[test$last_new_job=="never","last_new_job"]<-"0"
trainc[trainc$last_new_job==">4","last_new_job"]<-"5"
testc[test$last_new_job==">4","last_new_job"]<-"5"

trainc$last_new_job<-as.integer(trainc$last_new_job)
testc$last_new_job<-as.integer(testc$last_new_job)


#Trying to cluster the data into 2 clusters

km.12 <- kmeans(trainc%>% select(-c("target")), 2, nstart = 25)

fviz_cluster(km.12, data = trainc%>% select(-c("target")),
             palette = c("#2E9FDF", "#00AFBB"),#, "#E7B800", "#FC4E07"),
             ellipse.type = "euclid", # Concentration ellipse
             star.plot = TRUE, # Add segments from centroids to items
             repel = TRUE, # Avoid label overplotting (slow)
             ggtheme = theme_minimal()
)

```



```{r}
#Now we try to get the best preddictors using LASSO

X<-trainc %>% select(-c("target"))
Y<-trainc[,"target"]

x<-testc

cvfit <- glmnet::cv.glmnet(as.matrix(X), Y)
coef(cvfit, s = "lambda.1se")

coefplot(cvfit,lambda='lambda.1se', sort='magnitude')

```

```{r}
#We use Important Variables features of 'train' function (caret) to support the LASSO results.

train_control <- trainControl(method="repeatedcv", number=5, repeats=2)
svm3 <- train(as.factor(target) ~., data = trainc, method = "svmRadial", trControl = train_control, tuneLength = 5)
impVar <- varImp(svm3)
impVar
```

Judging from the outputs of both processes, the best predictors in decreasing order of their relevance are:

'city_4', 'experience', 'enrolled_university_2','major_discipline_3', 'last_new_job', 'relevent_experience_2', 'company_type_3',  'training_hours', 'target', 'company_size', 'education_level', 'city_5', 'major_discipline_2'

As a general rule of thumb we say that 10 or more predictors will overfit the training dataset. Keeping this in mind, 8 variables get close to overfitting, so we use some measure to counter it. Though the feature selection process might not always be helpful. We see 2 implementations to verify if it may be the case.


1. Weighted svm to tackle the class imbalance, using only the best performing features
2. Weighted svm to tackle the class imbalance, using all the features


First of all we will set a benchmark.

```{r}
#Benchmark

train.pred<- trainc %>% select(c('city_4', 'experience', 'enrolled_university_2','major_discipline_3', 'last_new_job', 'relevent_experience_2', 'company_type_3', 'training_hours', 'target', 'company_size', 'education_level', 'city_5', 'major_discipline_2'))

set.seed(7096)
sp<- sample.split(train.pred, SplitRatio = 0.7)
ftrain <- subset(train.pred, sp == "TRUE")
fvalid <- subset(train.pred, sp == "FALSE")

benchmark<-e1071::svm(as.factor(target)~.,data=ftrain,kernel="radial",type="C-classification",cross=2)

pvalid<-predict(benchmark,newdata= fvalid %>% select(-c("target")))
confusionMatrix(table(pvalid,as.factor(fvalid$target)))

```


As we can see, the standard SVM is completely biased towards the the negative class.

To counter this,

1. Weighted SVM(select features):

```{r}
#First we check the raio of the 2 classses present

r<-plyr::count(ftrain$target)[1,2]/plyr::count(ftrain$target)[2,2]
wts<-seq((r-r/5),(r+r/5),0.04)
wts
#We will iterate over wts to find the ideal weight for the positive class

bst.acc<-0
bst.wt<-1

for (w in wts){
  wt<-table(ftrain$target)
  wt[1]<-1
  wt[2]<-w
  tmp.mod<-e1071::svm(as.factor(target)~.,data=ftrain,kernel="radial",class.weights=wt,type="C-classification",cross=2)
  tmp.pred<-predict(tmp.mod,newdata= fvalid %>% select(-c("target")))
  c<-confusionMatrix(table(tmp.pred,as.factor(fvalid$target)))
  if (c$overall[1]>bst.acc){
    bst.acc<-c$overall[1]
    bst.wt<-w
  }
}
bst.acc
bst.wt

```


2. Weighted SVM(all features):

```{r}
#Weighted SVM with all features

train.pred<- trainc 

set.seed(7096)
sp<- sample.split(train.pred, SplitRatio = 0.7)
ftrain <- subset(train.pred, sp == "TRUE")
fvalid <- subset(train.pred, sp == "FALSE")
r<-plyr::count(ftrain$target)[1,2]/plyr::count(ftrain$target)[2,2]

wt<-table(ftrain$target)
wt[1]<-1
wt[2]<-r
tmp.mod<-e1071::svm(as.factor(target)~.,data=ftrain,kernel="radial",class.weights=wt,type="C-classification",cross=2)
tmp.pred<-predict(tmp.mod,newdata= fvalid %>% select(-c("target")))
c<-confusionMatrix(table(tmp.pred,as.factor(fvalid$target)))
c

```


As we can see, our feature selection techniques did not perform well compared to the standard implementation.